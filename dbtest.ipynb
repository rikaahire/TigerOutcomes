{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f95b42a-4e46-4a08-b464-db29df97c04b",
   "metadata": {},
   "source": [
    "Instructions for Keyring:\n",
    "\n",
    "Type the following commands into your terminal and input your netId and passwords. This is stored securely and python will ask for your system password to access them. This way, we avoid storing/hardcoding our credentials.\n",
    "\n",
    "`python -m keyring set TigerOutcomes_Service username_key`\n",
    "\n",
    "`python -m keyring set TigerOutcomes_Service password_key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "115073d5-4052-4bd9-b394-b79b66d1a540",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       mount [-dfrkuvw] special | mount_point (64)o options] [-t external_type] special mount_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Source  RecordYear Academic_Year_Degree_Awarded Degree_Track  \\\n",
      "0  Academic Analytics        2021                      2013-14           AB   \n",
      "1  Academic Analytics        2022                      2013-14           AB   \n",
      "2  Academic Analytics        2024                      2013-14           AB   \n",
      "3  Academic Analytics        2023                      2013-14           AB   \n",
      "4  Academic Analytics        2021                      2009-10           AB   \n",
      "\n",
      "       Degree_Descr Entity_Name Position UnitName  IPEDSID Country  \\\n",
      "0  Bachelor of Arts         NaN      NaN      NaN      NaN     NaN   \n",
      "1  Bachelor of Arts         NaN      NaN      NaN      NaN     NaN   \n",
      "2  Bachelor of Arts         NaN      NaN      NaN      NaN     NaN   \n",
      "3  Bachelor of Arts       Kawin  Founder      NaN      NaN      US   \n",
      "4  Bachelor of Arts         NaN      NaN      NaN      NaN     NaN   \n",
      "\n",
      "    Country_Name State State_Name   StudyID  \n",
      "0            NaN   NaN        NaN  COS28100  \n",
      "1            NaN   NaN        NaN  COS28100  \n",
      "2            NaN   NaN        NaN  COS28100  \n",
      "3  UNITED STATES    NY   New York  COS28100  \n",
      "4            NaN   NaN        NaN  COS24250  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keyring\n",
    "import pandas as pd\n",
    "\n",
    "# Define server path and mount path\n",
    "server_path = \"smb://files/dept/InstResearch/TigerOutcomes\"\n",
    "mount_path = \"/Volumes/TigerOutcomes\"  # Where the server will be mounted on your Mac\n",
    "\n",
    "# Retrieve credentials from Keychain\n",
    "username = keyring.get_password(\"TigerOutcomes_Service\", \"username_key\")\n",
    "password = keyring.get_password(\"TigerOutcomes_Service\", \"password_key\")\n",
    "\n",
    "# Mount the server using AppleScript for SMB connection\n",
    "os.system(f\"osascript -e 'do shell script \\\"mount volume \\\\\\\"{server_path}\\\\\\\" as user name \\\\\\\"{username}\\\\\\\" with password \\\\\\\"{password}\\\\\\\"\\\"'\")\n",
    "\n",
    "# Path to the Excel file on the mounted server\n",
    "file_path = f\"{mount_path}/COS333_AcA_Student_Outcomes.xlsx\"  # Replace 'file.xlsx' with your actual file name\n",
    "\n",
    "# Read the Excel file with pandas if the server is successfully mounted\n",
    "try:\n",
    "    df = pd.read_excel(file_path)\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"File not found. Check if the server is properly mounted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab342f3d-fcfa-48b6-918b-6776355b7656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def cosine_similarity_tfidf(target, job_titles):\n",
    "    # Vectorize the target and job titles together\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectors = vectorizer.fit_transform([target] + job_titles)\n",
    "    \n",
    "    # Calculate cosine similarity between target and each job title\n",
    "    target_vector = vectors[0]  # The first vector is for the target\n",
    "    similarity_scores = cosine_similarity(target_vector, vectors[1:])[0]  # Compare target to each job title\n",
    "\n",
    "    # Return similarity scores as a list\n",
    "    return similarity_scores.tolist()\n",
    "\n",
    "# Example usage\n",
    "target_job = \"Data Scientist\"\n",
    "job_titles_list = [\"Data Analyst\", \"Machine Learning Engineer\", \"Data Engineer\", \"Software Developer\"]\n",
    "tfidf_scores = cosine_similarity_tfidf(target_job, job_titles_list)\n",
    "print(\"TF-IDF Cosine Similarity Scores:\", tfidf_scores)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def cosine_similarity_bow(target, job_titles):\n",
    "    # Vectorize the target and job titles together\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectors = vectorizer.fit_transform([target] + job_titles)\n",
    "    \n",
    "    # Calculate cosine similarity between target and each job title\n",
    "    target_vector = vectors[0]  # The first vector is for the target\n",
    "    similarity_scores = cosine_similarity(target_vector, vectors[1:])[0]  # Compare target to each job title\n",
    "\n",
    "    # Return similarity scores as a list\n",
    "    return similarity_scores.tolist()\n",
    "\n",
    "# Example usage\n",
    "bow_scores = cosine_similarity_bow(target_job, job_titles_list)\n",
    "print(\"BoW Cosine Similarity Scores:\", bow_scores)\n",
    "\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load pre-trained word embeddings (e.g., GloVe, Word2Vec)\n",
    "# Make sure to point to the correct path to your embeddings file\n",
    "# e.g., word_vectors = KeyedVectors.load_word2vec_format(\"path/to/glove.6B.100d.txt\", binary=False)\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\"path/to/glove.6B.100d.txt\", binary=False)\n",
    "\n",
    "def average_word_embeddings(text, model, vector_size=100):\n",
    "    # Generate average word embeddings for the input text\n",
    "    words = text.lower().split()\n",
    "    embeddings = [model[word] for word in words if word in model]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(vector_size)\n",
    "\n",
    "def cosine_similarity_word_embeddings(target, job_titles, model, vector_size=100):\n",
    "    # Get the embedding for the target title\n",
    "    target_vector = average_word_embeddings(target, model, vector_size).reshape(1, -1)\n",
    "    \n",
    "    # Calculate cosine similarity between the target and each job title\n",
    "    similarity_scores = []\n",
    "    for title in job_titles:\n",
    "        title_vector = average_word_embeddings(title, model, vector_size).reshape(1, -1)\n",
    "        score = cosine_similarity(target_vector, title_vector)[0][0]\n",
    "        similarity_scores.append(score)\n",
    "    \n",
    "    return similarity_scores\n",
    "\n",
    "# Example usage\n",
    "embedding_scores = cosine_similarity_word_embeddings(target_job, job_titles_list, word_vectors, vector_size=100)\n",
    "print(\"Word Embeddings Cosine Similarity Scores:\", embedding_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
